{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Visualizations\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as pd\n",
    "\n",
    "\n",
    "# preprocessing\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.image import rgb_to_grayscale\n",
    "\n",
    "\n",
    "# Reshaping \n",
    "from tensorflow import reshape\n",
    "from tensorflow.image import resize_with_pad\n",
    "\n",
    "\n",
    "# Modelling \n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# metrics\n",
    "from tensorflow.keras.metrics import Recall, AUC\n",
    "\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Train Data From the Current Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get current working directory\n",
    "PATH = os.getcwd() + '/../../src/data/chest_xray/'\n",
    "\n",
    "\n",
    "# importing training normal data\n",
    "norm_train_path = PATH+'train/NORMAL/'\n",
    "norm_train_batch = os.listdir(norm_train_path) \n",
    "\n",
    "norm_train = []\n",
    "norm_errors = []\n",
    "for image_name in (norm_train_batch[:10]): \n",
    "    img_path = norm_train_path + image_name \n",
    "    try:\n",
    "        x = image.load_img(img_path) \n",
    "        # preprocessing if required \n",
    "        norm_train.append(x) \n",
    "    except:\n",
    "        norm_errors.append(image_name)\n",
    "    \n",
    "    \n",
    "# importing training pnuemonia data\n",
    "pnue_train_path = PATH + 'train/PNEUMONIA/'\n",
    "pnue_train_batch = os.listdir(pnue_train_path)\n",
    "\n",
    "pnue_train = []\n",
    "pnue_errors = []\n",
    "for image_name in pnue_train_batch[:10]:\n",
    "    img_path = pnue_train_path + image_name\n",
    "    try:\n",
    "        x = image.load_img(img_path)\n",
    "        pnue_train.append(x)\n",
    "    except:\n",
    "        pnue_errors.append(image_name)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define an import function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_image(PATH, image_name):\n",
    "    \"\"\"\n",
    "    PATH --> str: Relative path to image directoy\n",
    "    image_name --> str: Name of the image to load\n",
    "    \n",
    "    Returns:\n",
    "    PIL image\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    # create path to file\n",
    "    img_path = PATH + \"/\" + image_name\n",
    "    \n",
    "    # load file and return pil\n",
    "    return image.load_img(img_path) \n",
    "\n",
    "def grayscale_and_resize(PIL, shape=(256,256), padding=False):\n",
    "    \"\"\"\n",
    "    This is the preprocessing function that will take the raw jpeg, gray scale it, resize it and \n",
    "    turn it into an array\n",
    "    \n",
    "    \n",
    "    PIL --> PIL object\n",
    "    shape --> tuple: size of the final array\n",
    "    padding --> bool: if True, will use tf.resize_with_pad\n",
    "    \"\"\"\n",
    "    if padding:\n",
    "        gray_image = rgb_to_grayscale(PIL)\n",
    "        resized_image_arr = resize_with_pad(gray_image, target_height=shape[0], target_width=shape[1])\n",
    "    else:\n",
    "        resized_image_arr = img_to_array(PIL.convert(mode = 'L').resize(shape))\n",
    "    \n",
    "    return resized_image_arr\n",
    "\n",
    "\n",
    "def import_image_to_array(RELPATH,\n",
    "         dir_names = ['train', 'test', 'val'],\n",
    "         sub_dir_names = ['NORMAL', 'PNEUMONIA'],\n",
    "         padding=False,\n",
    "         shape=(256,256), test=False):\n",
    "    \"\"\"\n",
    "    This function loads all train, test and validation data into a dictionary of images\n",
    "    =====================================================================================\n",
    "    RELPATH --> str: The relative path to the cwd to the directory containing image directories\n",
    "    eg '../../src/data/chest_xray'\n",
    "    =====================================================================================\n",
    "    dir_names --> list, str: The names of the subdirectories containing the images\n",
    "    eg ['train', 'test', 'val'] <-- default\n",
    "    =====================================================================================\n",
    "    sub_dir_names --> list -> str: names of the subdirectory containg postivie and negative cases\n",
    "    \n",
    "    =====================================================================================\n",
    "    padding  --> bool: Whether you want the reshaping to be padded to or not\n",
    "    \n",
    "    =====================================================================================\n",
    "    shape --> tuple-> int: The final shape of the tensor array\n",
    "    \n",
    "    returns\n",
    "    \n",
    "    dict --> str:list -> tuple -> (tf.array, bool)\n",
    "    A dictionary where the keys are the dir_names and the values are lists containing tuple where \n",
    "    the first index is the tf.array and the second is a boolian, True if class is pnuemonia, false otherwise.\n",
    "    \"\"\"\n",
    "    # test relative path works!! \n",
    "    PATH = os.getcwd() + RELPATH\n",
    "    \n",
    "    try:\n",
    "        os.listdir(PATH)\n",
    "        print(\"You're relative directory is good, proceeding to import files...\", end=\"\\n\\n\")\n",
    "    except Exception as e:\n",
    "        print(str(e))\n",
    "        print(f\"Your relative path directory is not pointing to the correct location. Double check your input \\n\")\n",
    "        print(\"Terminating Program\", end='\\n')\n",
    "        print(\"=======================================================================================\")\n",
    "        return False\n",
    "    \n",
    "    \n",
    "    # instantiate a dict object and populate the keys\n",
    "    image_dict = {}\n",
    "    for name in dir_names:\n",
    "        image_dict[name] = []\n",
    "        \n",
    "        print(f\"Loading images from {name}\", end='\\n')\n",
    "        \n",
    "        \n",
    "        # For each subdirectory, get all of the images and append to dictionary\n",
    "        for sub_dir in sub_dir_names:\n",
    "            subPATH = PATH + name + \"/\" + sub_dir\n",
    "            # list of all image names in the subdirectory\n",
    "            image_batch = os.listdir(subPATH)\n",
    "            \n",
    "            for image in image_batch:\n",
    "                # import the image in pil format\n",
    "                pil = import_image(subPATH, image)\n",
    "                # gray scale and reshape the image turning it into an array\n",
    "                gray_resized_pil = grayscale_and_resize(pil, shape=shape, padding=padding)\n",
    "                \n",
    "                # center the pixels\n",
    "                centered_array = gray_resized_pil/255\n",
    "                \n",
    "                # append to the image_dict with class flag\n",
    "                flag = 1\n",
    "                if sub_dir == 'NORMAL':\n",
    "                    flag = 0\n",
    "                \n",
    "                image_dict[name].append((centered_array, flag))\n",
    "                \n",
    "            \n",
    "                # if this is just a test case, break out of this loop so we get one from each class\n",
    "                if test == True:\n",
    "                    break\n",
    "            \n",
    "            print(f\"Finished loading images from {sub_dir}\", end=\"\\n\")\n",
    "\n",
    "        print()\n",
    "    \n",
    "    return image_dict               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You're relative directory is good, proceeding to import files...\n",
      "\n",
      "Loading images from train\n",
      "Finished loading images from NORMAL\n",
      "Finished loading images from PNEUMONIA\n",
      "\n",
      "Loading images from test\n",
      "Finished loading images from NORMAL\n",
      "Finished loading images from PNEUMONIA\n",
      "\n",
      "Loading images from val\n",
      "Finished loading images from NORMAL\n",
      "Finished loading images from PNEUMONIA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "images = import_image_to_array('/../../src/data/chest_xray/',test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check for class imbalance in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate inverse \n",
    "pnue_frequency = sum(y_train)/len(y_train)\n",
    "inv_pnue_frequency = 1/pnue_frequency\n",
    "\n",
    "normal_frequency = (len(y_train)-sum(y_train))/len(y_train)\n",
    "inv_normal_frequency = 1/normal_frequency\n",
    "\n",
    "weights = {\n",
    "    0: inv_normal_frequency,\n",
    "    1: inv_pnue_frequency\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.array([i[1] for i in images['train']])\n",
    "X_train = np.array([i[0] for i in images['train']])  \n",
    "X_test = np.array([i[0] for i in images['test']])\n",
    "y_test = np.array([i[1] for i in images['test']])\n",
    "X_val = np.array([i[0] for i in images['val']])\n",
    "y_val = np.array([i[1] for i in images['val']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = models.Sequential()\n",
    "adam = Adam()\n",
    "recall = Recall()\n",
    "AUC = AUC()\n",
    "# Input layer conv\n",
    "cnn.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,  1)))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# First hidden layer conv\n",
    "cnn.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(layers.Flatten())\n",
    "\n",
    "# Added first dense layer\n",
    "cnn.add(layers.Dense(32, activation='relu'))\n",
    "cnn.add(layers.Dropout(.2))\n",
    "\n",
    "# Add Second Layer\n",
    "cnn.add(layers.Dense(16, activation='relu'))\n",
    "cnn.add(layers.Dropout(.1))\n",
    "\n",
    "cnn.add(layers.Dense(1, activation='sigmoid'))\n",
    "cnn.compile(loss='binary_crossentropy',\n",
    "              optimizer= adam,\n",
    "              metrics=['acc', recall, AUC])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 39/105 [==========>...................] - ETA: 5:46 - loss: 0.0639 - acc: 0.9882 - recall_7: 0.9883 - auc_2: 0.9995"
     ]
    }
   ],
   "source": [
    "cnn1 = cnn.fit(X_train, y_train,\n",
    "               epochs=10,\n",
    "               batch_size=50,\n",
    "               validation_data = (X_val, y_val), \n",
    "               class_weight=weights,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model. The validation accuracy with the test data is low, but let's look at the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 1ms/step - loss: 0.0045 - acc: 1.0000 - recall_7: 1.0000 - auc_2: 1.0000\n"
     ]
    }
   ],
   "source": [
    "validation1_1 = cnn.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation1_3 = cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 84s 515ms/step - loss: 0.6925 - acc: 0.7429 - recall_6: 1.0000 - auc_1: 0.5000\n"
     ]
    }
   ],
   "source": [
    "validation1_ = cnn3.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../../models/2020-12-011.HDF5/assets\n"
     ]
    }
   ],
   "source": [
    "today = str(datetime.today()).split()[0]\n",
    "directory = \"../../models/\"\n",
    "model_id = \"tim-1\"\n",
    "file = directory+today+model_number+\".HDF5\"\n",
    "cnn.save(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 2ms/step - loss: 0.0045 - acc: 1.0000 - recall_7: 1.0000 - auc_2: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.004549574572592974, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cnn = models.load_model(\"../../models/2020-12-011.HDF5/\")\n",
    "\n",
    "cnn.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 16s 796ms/step - loss: 1.7555 - acc: 0.7788 - recall_7: 0.9872 - auc_2: 0.8070\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.7555465698242188,\n",
       " 0.7788461446762085,\n",
       " 0.9871794581413269,\n",
       " 0.8070019483566284]"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_46 (Conv2D)           (None, 254, 254, 64)      640       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 127, 127, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_47 (Conv2D)           (None, 125, 125, 32)      18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 62, 62, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_17 (Flatten)         (None, 123008)            0         \n",
      "_________________________________________________________________\n",
      "dense_50 (Dense)             (None, 32)                3936288   \n",
      "_________________________________________________________________\n",
      "dropout_39 (Dropout)         (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_40 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 3,955,937\n",
      "Trainable params: 3,955,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second model\n",
    "\n",
    "I added a second hidden layer and I added dropout = 0.1 to the input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/105 [..............................] - ETA: 0s - loss: 1.4348 - acc: 0.5000 - recall_13: 0.5135 - auc_3: 0.4553"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-291-804564b09e45>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m                \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m                verbose=True)\n\u001b[0m",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m/Users/TjH/opt/anaconda3/envs/learn-env/lib/python3.6/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "cnn2 = models.Sequential()\n",
    "adam2 = Adam()\n",
    "recall = Recall()\n",
    "AUC = AUC()\n",
    "\n",
    "# Input Layer conv\n",
    "cnn2.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,1)))\n",
    "cnn2.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn2.add(layers.Dropout(0.1))\n",
    "\n",
    "# First hidden Layer conv\n",
    "cnn2.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn2.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn2.add(layers.Dropout(0.5))\n",
    "\n",
    "# Second hidden Layer conv\n",
    "cnn2.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "cnn2.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn2.add(layers.Dropout(0.5))\n",
    "cnn2.add(layers.Flatten())\n",
    "\n",
    "# Added first Layer dense\n",
    "cnn2.add(layers.Dense(32, activation='relu'))\n",
    "cnn2.add(layers.Dropout(.5))\n",
    "\n",
    "# Add Second Layer dense\n",
    "cnn2.add(layers.Dense(16, activation='relu'))\n",
    "cnn2.add(layers.Dropout(.5))\n",
    "\n",
    "# Output Layer dense\n",
    "cnn2.add(layers.Dense(1, activation='sigmoid'))\n",
    "cnn2.compile(loss='binary_crossentropy',\n",
    "              optimizer= adam2,\n",
    "              metrics=['acc', recall, AUC])\n",
    "\n",
    "history2 = cnn2.fit(X_train, y_train,\n",
    "               epochs=5,\n",
    "               batch_size=50,\n",
    "               validation_data = (X_test, y_test), \n",
    "               class_weight=weights,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.today()).split()[0]\n",
    "directory = \"../../models/\"\n",
    "model_id = \"tim-2\"\n",
    "file = directory+today+model_number+\".HDF5\"\n",
    "cnn.save(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation2_ = cnn2.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation2_2 = cnn2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation2_3 = cnn2.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn3 = models.Sequential()\n",
    "adam3 = Adam()\n",
    "recall3 = Recall()\n",
    "AUC3 = AUC()\n",
    "# Input Layer conv\n",
    "cnn3.add(layers.Conv2D(64, (3, 3), activation='relu', input_shape=(256, 256,1)))\n",
    "cnn3.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn3.add(layers.Dropout(0.1))\n",
    "\n",
    "# First hidden Layer conv\n",
    "cnn3.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "cnn3.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn3.add(layers.Dropout(0.5))\n",
    "\n",
    "# Second hidden Layer conv\n",
    "cnn3.add(layers.Conv2D(16, (3, 3), activation='relu'))\n",
    "cnn3.add(layers.MaxPooling2D((2, 2)))\n",
    "cnn3.add(layers.Dropout(0.5))\n",
    "cnn3.add(layers.Flatten())\n",
    "\n",
    "# Added first Layer dense\n",
    "cnn3.add(layers.Dense(32, activation='relu'))\n",
    "cnn3.add(layers.Dropout(.5))\n",
    "\n",
    "# Add Second Layer dense\n",
    "cnn3.add(layers.Dense(16, activation='relu'))\n",
    "cnn3.add(layers.Dropout(.5))\n",
    "\n",
    "# Output Layer dense\n",
    "cnn3.add(layers.Dense(1, activation='sigmoid'))\n",
    "cnn3.compile(loss='binary_crossentropy',\n",
    "              optimizer= adam2,\n",
    "              metrics=['acc', recall3, AUC3])\n",
    "\n",
    "history3 = cnn3.fit(X_train, y_train,\n",
    "               epochs=10,\n",
    "               batch_size=50,\n",
    "               validation_data = (X_test, y_test), \n",
    "               class_weight=weights,\n",
    "               verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation3_ = cnn3.evaluate(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation3_2 = cnn3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation3_3 = cnn3.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "today = str(datetime.today()).split()[0]\n",
    "directory = \"../../models/\"\n",
    "model_id = \"tim-3\"\n",
    "file = directory+today+model_number+model_id+\".HDF5\"\n",
    "cnn3.save(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
